<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="VisInContext">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>VisInContext</title>

  <!-- Bootstrap -->
  <link href="static/css/bootstrap-4.4.1.css" rel="stylesheet">
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./assets/parrot.jpg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title" style="margin-bottom: 0"><img src="./assets/avatar.png" width="80" class="center"><strong>Leveraging Visual Tokens for Extended Text Contexts in Multi-Modal Learning</strong></h1>
          <!-- <h1 class="title is-2" style="margin-bottom: 0;color: red"><strong>CLIP Score is Innately Flawed !!!</strong></h1> -->

          <div class="column is-full_width">
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://fingerrec.github.io/">Wang, Alex Jinpeng</a><sup>1</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=WR875gYAAAAJ&hl=en"> Li, Linjie </a><sup>2</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <a href="">Yang , Zhengyuan </a><sup>1</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
            </span> 
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=cDcWXuIAAAAJ&hl=zh-CN">Wang, Lijuan  </a><sup>2</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <a href="">Li, Min </a><sup>3</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>National University of Singapore</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><sup>2</sup>Microsoft</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><sup>3</sup>Central South University </span>&nbsp;&nbsp;&nbsp;&nbsp;
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2406.02547"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/showlab/visincontext"
                   class="external-link button is-normal is-rounded is-dark disabled">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Github</span>
                  </a>
              </span>

            </div>
          </div>

        </div>
        </div>
      </div>
    </div>
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <!-- Highlights -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="margin-top: -30px">Summary</h2>
        <div class="content has-text-justified">
          <ul>
            <li style="font-size:16px">We introduce Visualized In-Context Text Processing (VisInContext), a novel method that <strong> increases in-context text length using visual tokens.</strong></li>
            <li style="font-size:16px">We demonstrate that VisInContext is effective for both training and inference stage with much lower computational cost.</li>
            <li style="font-size:16px">As a byproduct, our method also shows great potential in document understanding on popular document QA tasks and our newly proposed sequential document retrieval task.</li>
          </ul>

        </div>
      </div>
    </div>
    
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3  has-text-centered" style="margin-top: -20px">Overview</h2>

        <img src="./assets/main_ppl.png" class="center">

        <h2 class="subtitle" style="margin-top: 15px; font-size: 17px">
          <li>    
            The VisInContext pipeline builds upon the Flamingo model for in-context few-shot modeling (represented in gray).
    VisInContext processes interleaved image-text data by rendering portions of the in-context text into images. This approach maintains the <i>Text Token Length</i> of the model while allowing for a significantly extended <i>In-context Text Length</i>.
   </li>
        </h2>

      </div>
    </div>

  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -20px">OCR Validation</h2>

        <div class="columns is-centered" style="display: flex; justify-content: center;">
          <div class="column is-full-width" style="display: flex; justify-content: center;">
            <img src="./assets/ocr_val.png" style="width: 70%; margin: auto;">
          </div>
        </div>
        

        <h2 class="subtitle" style="margin-top: 15px; font-size: 17px">
          <li> The OCR ability is highly improved with VisInContext. </li>
        </h2>

      </div>
    </div>

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -20px"> Text Image Experiments </h2>
        <div class="content has-text-justified">
          <table>
            <tr>
              <td>Method</td>
              <td>Text Source</td>
              <td>Text Tokens</td>
              <td>T-Shots</td>
              <td>OK-VQA</td>
              <td>TextVQA</td>
              <td>VizWiZ</td>
              <td>VQAV2</td>
              <td>COCO</td>
              <td>Flickr</td>
              <td>Mean</td>
            </tr>
            <tr>
              <td>Open-Flamingo9B Baseline<sup>†</sup></td>
              <td>Raw Text</td>
              <td style="color:#52c256;">10</td>
              <td>0</td>
              <td>18.1</td>
              <td>14.8</td>
              <td>21.5</td>
              <td>26.5</td>
              <td>40.1</td>
              <td>32.1</td>
              <td>25.5</td>
            </tr>
            <tr>
              <td></td>
              <td></td>
              <td style="color:#1d44b0;">62</td>
              <td>4</td>
              <td><u>23.8</u></td>
              <td>18.1</td>
              <td><u>23.7</u></td>
              <td><strong>40.5</strong></td>
              <td>57.5</td>
              <td>35.3</td>
              <td>33.2<span style="color:rgb(73, 0, 128);">(7.7↑)</span></td>
            </tr>
            <tr>
              <td></td>
              <td></td>
              <td style="color:#b42222;">426</td>
              <td>32</td>
              <td><strong>25.2</strong></td>
              <td>16.4</td>
              <td><strong>25.5</strong></td>
              <td>34.6</td>
              <td><strong>66.1</strong></td>
              <td><strong>38.5</strong></td>
              <td><strong>34.4<span style="color:green;">(8.9↑)</span></strong></td>
            </tr>
            <tr>
              <td>+ModelName</td>
              <td>+Rendered Image</td>
              <td style="color:#52c256;">10</td>
              <td>0</td>
              <td>16.2</td>
              <td>16.8</td>
              <td>15.4</td>
              <td>30.6</td>
              <td>42.3</td>
              <td>33.5</td>
              <td>25.8</td>
            </tr>
            <tr>
              <td></td>
              <td></td>
              <td style="color:#52c256;">10</td>
              <td>4</td>
              <td>17.2</td>
              <td><u>21.8</u></td>
              <td>19.7</td>
              <td>35.2</td>
              <td>52.4</td>
              <td>35.2</td>
              <td>30.3<span style="color:green;">(4.5↑)</span></td>
            </tr>
            <tr>
              <td></td>
              <td></td>
              <td style="color:#52c256;">10</td>
              <td>32</td>
              <td>21.3</td>
              <td><strong>22.6</strong></td>
              <td>21.5</td>
              <td><u>38.8</u></td>
              <td><u>60.3</u></td>
              <td><u>37.0</u></td>
              <td><strong><u>33.6<span style="color:green;">(7.8↑)</span></u></strong></td>
            </tr>
          </table>
          <p style="font-size:small;">
            <strong>VisInContext effectively incorporates in-context text with visual tokens, demonstrating significant performance improvements with consistent token usage.</strong><br> Here, T-shots refer to text-only in-context examples. Tokens indicate the length of the input to the LLM. Text source describes the preprocessing method for in-context examples. <sup>†</sup> denotes our implementation on 180M pretraining data.
          </p>
          
        </h2>
      </div>
      
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -20px"> Few-shot Modeling Ability Evaluation </h2>
        <div class="content has-text-justified">
<div class="content has-text-justified">
  <table>
    <tr>
      <td>Method</td>
      <td>Text</td>
      <td>ICL Tokens&nbsp;&uarr;</td>
      <td>Shots</td>
      <td>OK-VQA</td>
      <td>TextVQA</td>
      <td>VizWiZ</td>
      <td>VQAV2</td>
      <td>COCO</td>
      <td>Flickr</td>
      <td>HM</td>
      <td>Mean</td>
    </tr>
    <tr>
      <td>Open-Flamingo MOE<sup>†</sup></td>
      <td>Raw Text</td>
      <td>256</td>
      <td>0</td>
      <td>40.2</td>
      <td>21.3</td>
      <td>23.3</td>
      <td>47.8</td>
      <td>82.3</td>
      <td>59.4</td>
      <td>60.4</td>
      <td>47.8</td>
    </tr>
    <tr>
      <td></td>
      <td></td>
      <td></td>
      <td>4</td>
      <td>42.5</td>
      <td>22.2</td>
      <td>32.2</td>
      <td>49.8</td>
      <td>90.5</td>
      <td>63.5</td>
      <td>63.8</td>
      <td>52.1</td>
    </tr>
    <tr>
      <td></td>
      <td></td>
      <td></td>
      <td>32</td>
      <td><strong>46.8</strong></td>
      <td>23.2</td>
      <td>40.5</td>
      <td>49.9</td>
      <td><u>98.2</u></td>
      <td><u>66.2</u></td>
      <td><strong>66.0</strong></td>
      <td><u>55.8</u></td>
    </tr>
    <tr>
      <td>+ ModelName</td>
      <td>+ Rendered Image</td>
      <td><strong>2048</strong></td>
      <td>0</td>
      <td>39.5</td>
      <td>26.4</td>
      <td>26.3</td>
      <td>48.5</td>
      <td>84.4</td>
      <td>60.5</td>
      <td>62.2</td>
      <td>49.7</td>
    </tr>
    <tr>
      <td></td>
      <td></td>
      <td></td>
      <td>4</td>
      <td>44.3</td>
      <td>28.9</td>
      <td>32.0</td>
      <td><u>50.3</u></td>
      <td>94.2</td>
      <td>65.3</td>
      <td><u>65.5</u></td>
      <td>54.4</td>
    </tr>
    <tr>
      <td></td>
      <td></td>
      <td></td>
      <td>32</td>
      <td><u>46.3</u></td>
      <td><strong>31.2</strong></td>
      <td><strong>41.2</strong></td>
      <td><strong>51.0</strong></td>
      <td><strong>101.3</strong></td>
      <td><strong>68.4</strong></td>
      <td>65.2</td>
      <td><strong>57.8</strong></td>
    </tr>
  </table>
  <p style="font-size:small;">
    <strong>Increasing in-context text length with ModelName significantly improves performance on multi-modality downstream tasks.</strong><br>
    The model is pre-trained with a 56B MOE model. ICL stands for in-context text length. HM is short for hatefulmemes. With ModelName, we increase the ICL from 256 to 2048, leading to clear improvements over the baseline. <sup>†</sup> indicates our implementation.
  </p>
</div> 


</div>
</div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title" style="margin-top: -60px">BibTeX</h2>
    <pre>
      <code>
        @article{wang2024visincontext,
          title={Leveraging Visual Tokens for Extended Text Contexts in Multi-Modal Learning},
          author={Wang, Alex Jinpeng and Li, Linjie and Lin, Yiqi and Li, Min  and Wang, Lijuan and Shou, Mike Zheng},
          journal={arXiv preprint arXiv:2406.02547},
          year={2024}
        }

      </code></pre>
  </div>
</section>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
    <td>
      <br>
      <p align="center">
        <font size="2">
          <a href="https://github.com/nerfies/nerfies.github.io">
            <font size="2" color="lightgray">awesome webpage template</font>
          </a>
          <br>
        </font>
      </p>
      <br>
    </td>
  </tr>
</table>

</body>
</html>
