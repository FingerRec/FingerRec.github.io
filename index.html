
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252" charset="utf-8">
        <title>Jinpeng Wang - PHD, National University of Singaoire </title>
<style type="text/css"></style></head>
    <body><table border="0" width="980px" align="center"><tbody><tr><td>
    
        </td><td valign="top">
<!--            <img src="images/cmuscslogo.gif">
                <img src="images/rilogo.png"> -->
        <br>
        <table style="font-size: 11pt;" border="0" width="100%">
            <tbody><tr>
                <td width="50%">
                    <!-- <img width="300" src="./index_files/mypic.jpeg" border="0"> -->
                    <!-- <img width="300" src="./index_files/mypic2.jpg" border="0"> -->
                    <img width="230" src="./index_files/jinpeng/my_photo.jpg" border="0" style="border-radius: 50%;overflow: hidden">
                </td>
                <td>
                    <font face="helvetica , ariel, &#39;sans serif&#39;" size="6"> 
                        <b>Jinpeng Wang</b><br><br>
                    </font>
                    <font face="helvetica , ariel, &#39;sans serif&#39;" size="4"> 
                        PHD Candidate<br>
                        National University of Singapore (NUS)<br>
                        Singapore<br><br>
                        jinpengwang at u.nus.edu<br>
                        [<a href="https://github.com/fingerrec" border="0">GitHub</a>]
                        [<a href="https://scholar.google.com/citations?user=UtaAVacAAAAJ&hl=zh-CN" border="0">Google Scholar</a>]<br>
                        [<a href="https://www.semanticscholar.org/author/Jinpeng-Wang/48093158" border="0">Semantic Scholar</a>]<br>
                        [<a href="index_files/CV.pdf" border="0">Resume/CV</a>]
                        [<a href="https://twitter.com/awinyimgprocess" border="0">Twitter</a>]
                        [<a href="bio.txt" border="0">Bio</a>]<br>
                    </font>
                </td>
            </tr>
        </tbody></table> 
        <p>
        </p><hr size="2" align="left" noshade="">
        <p>
        
        <font face="helvetica, ariel, &#39;sans serif&#39;"> 
        <!--</font></p><h2><font face="helvetica, ariel, &#39;sans serif&#39;">About Me</font></h2><font face="helvetica, ariel, &#39;sans serif&#39;">-->
            <!--and my supervisor is <a href="https://scholar.google.com.hk/citations?user=nhghITMAAAAJ&hl=en">Andy Jinhua Ma</a>-->
        My research interests are in computer vision especially video representation learning. I obtained my bachelor degree and master degree in Sun Yat-Sen University (SYSU). I'm currently a PHD  Candidate in National University of Singapore (NUS) wih Prof. <a href="http://www.columbia.edu/~zs2262/"> Mike Zheng Shou</a>.
        <!-- <br><br> -->
        </p><hr size="2" align="left" noshade="">

        <h3>News   <img width="50" align="center" src="./imgs/news_gif2.gif" border="0"> &nbsp </h3>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <span style="font-size: 10pt;">
            <!--<b>[July 2021]</b> I'll join the Tencent PCG as a research internship these days.  <br>-->
            <b>[July 2021]</b> Congratulation! Our paper "Learning Spatio-temporal Representation by Channel Aliasing Video Perception" has been accepted by ACM MM.  <br>
            <b>[July 2021]</b> I was awarded the excellent master graduation thesis (1/224).  <br>
            <b>[June 2021]</b> Our paper "Multi-level Temporal Dilated Dense Prediction for Action Recognition" has been published in IEEE Transactions on MultiMedia (TMM) (IF: 6.1). <a href="https://scholar.google.com.hk/citations?user=nhghITMAAAAJ&hl=en">URL </a> <br>
            <b>[Apr 2021]</b> Congratulation!!! I will take part in <a href="https://sites.google.com/view/showlab">Show Lab </a> at the August of this year. <br>
            <b>[Mar 2021]</b> I was invited to give a talk in VALSE-semanir in 3.28. Weclome to take part in us! <a href="https://mp.weixin.qq.com/s/b7ypH650J3v5pf_Qm7B22w">Link!</a><br>
                <b>[Mar 2021]</b> Our BE was recommended to CVer! <a href="https://mp.weixin.qq.com/s/HNVautdcOCOCqRllUhM7Tg">Link!</a>><br>
            <b>[Mar 2021]</b> I will serve as a reviewer for ICCV2021!<br>
            <b>[Mar 2021]</b> Our works on video self-supervised learning were accepted to CVPR!<br>
            <b>[Mar 2021]</b> Our work on self-supervised mutual learning was accepted to ICME!<br>
            <b>[Jan 2021]</b> I will serve as a reviewer for CVPR2021!<br>
            <b>[Oct 2020]</b> Our work on using contrastive learning for video action recognition was accepted to AAAI!<br>
            <b>[Aug 2020]</b> The code for our 3D Net Visualization has been relased in  <a href="https://github.com/FingerRec/3DNet_Visualization"> My Github</a>, support no-label visualization.<br>
            <b>[Apr 2020]</b> Our work on action recognition with dense prediction network was accepted to TCSVT!<br>
            <b>[Feb 2018]</b> The code for our real time action recognition has been relased in  <a href="https://github.com/FingerRec/real_time_video_action_recognition"> My Github</a>,
            <!-- <b>[Feb 2020]</b> I served as an Area Chair for CVPR 2020 and spoke on <a href="https://www.youtube.com/watch?v=aNDwHRxWTa0">Analyzing CNN Artifacts in Discriminative and Generative Models</a> (11 min). The second half includes our "Detecting CNN-generated images" work, just accepted to CVPR.<br> -->
            <!-- <b>[Dec 2019]</b> See our new work on detecting CNN-generated images below.<br> -->
            <!-- <b>[Nov 2019]</b> I presented our "Detecting Photoshop" ICCV19 work at <a href="https://www.youtube.com/watch?v=21lj8tCSMkg">Adobe MAX</a> (5 min), on stage with John Mulaney (aka Peter Porker/Spider-Ham)!<br> -->
            <!-- <b>[Oct 2019]</b> Thank you <a href="https://twitter.com/Oxford_VGG/status/1184087868857290752">Oxford</a> and UCL for hosting me.<br> -->
            <!-- <b>[Oct 2019]</b> This <a href="http://video.tv.adobe.com/v/28291">video</a> shows interactive colorization in Photoshop Elements 2020, based on our SIGGRAPH 2017 work.<br> -->
            <!-- <b>[Sept 2019]</b> See our new work on interactive sketch to image synthesis below.<br> -->
            <!-- <b>[Jun 2019]</b> See our new work on detecting Photoshopped images below.<br> -->
            <!-- <b>[May 2019]</b> Our work on anti-aliasing convolutional networks has been accepted to ICML 2019. Try anti-aliasing your convnet <a href="https://github.com/adobe/antialiased-cnns">here</a>!<br> -->
            <!-- <b>[Aug 2018]</b> I will be presenting at the Thesis Fast Forward session at SIGGRAPH on Tuesday 8/14, 2:00pm.<br> -->
            <!-- <b>[Jun 2018]</b> We will be presenting our <a href="https://richzhang.github.io/PerceptualSimilarity/">project</a> on perceptual metrics at CVPR, Tuesday 6/19, 10:10am. Try our metric <a href="https://github.com/richzhang/PerceptualSimilarity">here</a>!<br> -->
            <!-- <b>[May 2018]</b> I have <a href="./index_files/graduation.jpg">graduated</a> from UC Berkeley and have joined Adobe Research as a Research Scientist in San Francisco! -->
            </span>

<!--         </p><hr size="2" align="left" noshade="">

        <h3>Internship </h3>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <span style="font-size: 10pt;"> -->
            <!-- If you have similar interests and are interested in collaborating during a summer 2021 internship, I'd be happy to hear from you. <b>Please apply <a href="https://research.adobe.com/internships">here</a></b> and then -->
            <!-- I would be also happy to hear from you. <b>Timing-wise, please contact me after the CVPR deadline (Nov 16)</b>, unless you have expiring offers. This is because I am still focusing on current projects and do not know headcount for next year. -->
            <!-- tell me about your past research experience and what you would potentially like to do. The goal of an internship is a publication, usually CVPR or SIGGRAPH. Interns are typically PhD students; the number of slots is limited, so we unfortunately cannot accept everyone. -->
            <!-- </span> -->
        <!-- </font> -->

        </p><hr size="2" align="left" noshade="">

        <h2>Publications </h2>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <table cellspacing="15">
				<tbody>
                
                <!-- <tr><td width="30%" align=left>
                <span style="font-size: 16pt;"><b>2020</b></span>
                </td></tr>
                -->

                <tr>
                    <td width="30%" align=center>
                    <!-- height="74" -->
                        <!-- <center> -->
                        <img width="260" align="center" src="index_files/jinpeng/papers/ACMMM2021/resources/Intro.png" border="0"> &nbsp;
                        <!-- </center> -->
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Learning Spatio-temporal Representation by Channel Aliasing video Perception.</b> <br>
                        <span style="font-size: 10pt;">
                        Yiqi Lin, Jinpeng Wang (equal contribution), Manlin  Zhang,  <a href="https://scholar.google.com.hk/citations?user=nhghITMAAAAJ&hl=en">Andy J. Ma</a> <br>
                        To appear in ACM MM, 2021. <br>
                        [<a href="">Paper</a>]
                        [<a href="">Bibtex</a>]
                        <br>
                    </td>
                </tr>
                <tr>
                    <td width="30%" align=center>
                    <!-- height="74" -->
                        <!-- <center> -->
                        <img width="260" align="center" src="index_files/jinpeng/papers/TMM2021/resources/mtp_illustration.jpg" border="0"> &nbsp;
                        <!-- </center> -->
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Multi-level Temporal Dilated Dense Prediction for Action Recognition</b> <br>
                        <span style="font-size: 10pt;">
                        Jinpeng Wang, Yiqi Lin, Manlin  Zhang,  Yuan Gao, <a href="https://scholar.google.com.hk/citations?user=nhghITMAAAAJ&hl=en">Andy J. Ma</a> <br>
                        To appear in TMM, 2021. <br>
                        [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9447897">Paper</a>]
                        [<a href="./index_files/jinpeng/papers/TMM2021/resources/bibtex.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>


                <tr>
                    <td width="30%" align=center>
                    <!-- height="74" -->
                        <!-- <center> -->
                        <img width="260" align="center" src="index_files/jinpeng/papers/CVPR2021/resources/teaser.png" border="0"> &nbsp;
                        <!-- </center> -->
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Removing the Background by Adding the Background: Towards Background Robust Self-supervised Video Representation Learning</b> <br>
                        <span style="font-size: 10pt;">
                        Jinpeng Wang, Yuting Gao, Ke Li, Yiqi Lin, <a href="https://scholar.google.com.hk/citations?user=nhghITMAAAAJ&hl=en">Andy J. Ma</a>, Hao Cheng, Pai Peng, <a href="https://mac.xmu.edu.cn/rrji/">Rongrong Ji</a>, <a href="https://www.eee.hku.hk/~sunxing/"> Xing Sun</a>  <br>
                        To appear in CVPR, 2021. <br>
                        [<a href="https://arxiv.org/abs/2009.05769">Paper</a>]
                        [<a href="./index_files/jinpeng/papers/CVPR2021/project_website.html">Webpage</a>]
                        [<a href="https://www.youtube.com/embed/aFzno6CQcyE">Video</a>]
                        [<a href="https://github.com/FingerRec/BE">GitHub</a>]
                        [<a href="./index_files/jinpeng/papers/CVPR2021/resources/bibtex.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>

                <tr>
                    <td width="30%" align=center>
                    <!-- height="74" -->
                        <!-- <center> -->
                        <img width="260" height="180" align="center" src="index_files/jinpeng/papers/ICME2021/ICME_teaser.jpg" border="0"> &nbsp;
                        <!-- </center> -->
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Self-supervised Mutual Learning For Video Representation Learning</b> <br>
                        <span style="font-size: 10pt;">
                         Jinpeng Wang, Yutong Li, Jianguo Hu, Xuebing Yang, Yanyu Ding  <br>
                        To appear in ICME, 2021. <br>
                        [<a href="">Paper</a>]
                        [<a href="">Bibtex</a>]
                        <br>
                    </td>
                </tr>
                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <!-- <center> -->
                          <!-- <center> -->
                        <img width="260" align="center" src="./index_files/jinpeng/papers/AAAI2021/spatial_warpping.png" border="0"> &nbsp;
                        <!-- </center> -->
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b> Enhancing Unsupervised Video Representation Learning by Decoupling the Scene and the Motion </b> <br>
                        <span style="font-size: 10pt;">
                        <span style="font-size: 10pt;"> Jinpeng Wang, Yuting Gao, Ke Li, Jianguo Hu, Xinyang Jiang, Xiaowei Guo, <a href="https://mac.xmu.edu.cn/rrji/">Rongrong Ji</a>, <a href="https://www.eee.hku.hk/~sunxing/"> Xing Sun</a> <br>
                        In AAAI, 2021. <br>
                        [<a href="https://arxiv.org/abs/2009.05757">Paper</a>]
                        [<a href="./index_files/jinpeng/papers/AAAI2021/project_website.html">Webpage</a>]
                        [<a href="">Video</a>]
                        [<a href="https://github.com/FingerRec/DSM-decoupling-scene-motion">GitHub</a>]
                        [<a href="">Bibtex</a>]
                        <br>
                    </td>
                </tr>


                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <!-- <center> -->
                          <!-- <center> -->
                        <img width="260" align="center" src="./index_files/jinpeng/papers/TCSVT2020/tcsvt_heatmap.png" border="0"> &nbsp;
                        <!-- </center> -->
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b> Revisiting Hard Example for Action Recognition </b> <br>
                        <span style="font-size: 10pt;">
                        <span style="font-size: 10pt;"> Jinpeng Wang, Jianguo Hu, Shiren Li, Zhihao Yuan <br>
                        In TCSVT, 2020. <br>
                        [<a href="https://ieeexplore.ieee.org/document/9026815">Paper</a>]
                        [<a href="https://github.com/FingerRec/RHE">GitHub</a>]
                        [<a href="">Bibtex</a>]
                        <br>
                    </td>
                </tr>


                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <!-- <center> -->
                          <!-- <center> -->
                        <img width="260" align="center" src="./index_files/jinpeng/papers/ICASSP2020/background.png" border="0"> &nbsp;
                        <!-- </center> -->
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b> Rethinking Temporal-Related Sample for Human Action Recognition </b> <br>
                        <span style="font-size: 10pt;">
                        <span style="font-size: 10pt;">Jinpeng Wang, Shiren Li, Zhikui Duan, Zhihao Yuan  <br>
                        In ICASSP, 2020. <br>
                        [<a href="https://ieeexplore.ieee.org/document/9053794">Paper</a>]
                        [<a href="">Bibtex</a>]
                        <br>
                    </td>
                </tr>


                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <!-- <center> -->
                          <!-- <center> -->
                        <img width="260" align="center" src="./index_files/jinpeng/papers/NeuroComputing2020/neurocomputing_teaser.png" border="0"> &nbsp;
                        <!-- </center> -->
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b> Adversarial open set domain adaptation via progressive selection of transferable target samples </b> <br>
                        <span style="font-size: 10pt;">
                        <span style="font-size: 10pt;"> Yuan Gao, <a href="https://scholar.google.com.hk/citations?user=nhghITMAAAAJ&hl=en">Andy J. Ma</a>, Yue Gao, Jinpeng Wang, Youngsun Pan <br>
                        In NeuroComputing, 2020. <br>
                        [<a href="https://www.sciencedirect.com/science/article/pii/S0925231220308675">Paper</a>]
                        [<a href="">Bibtex</a>]
                        <br>
                    </td>
                </tr>

                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <!-- <center> -->
                          <!-- <center> -->
                        <img width="260" align="center" src="./index_files/jinpeng/papers/WACV2020/wacv_teaser.png" border="0"> &nbsp;
                        <!-- </center> -->
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b> Multi-Scale Adversarial Cross-Domain Detection with Robust Discriminative Learning </b> <br>
                        <span style="font-size: 10pt;">
                        <span style="font-size: 10pt;"> Youngsun Pan, <a href="https://scholar.google.com.hk/citations?user=nhghITMAAAAJ&hl=en">Andy J. Ma</a>, Yuan Gao, Jinpeng Wang, Yiqi Lin <br>
                        In WACV, 2020. <br>
                        [<a href="https://ieeexplore.ieee.org/document/9093287">Paper</a>]
                        [<a href="">Bibtex</a>]
                        <br>
                    </td>
                </tr>

                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <!-- <center> -->
                          <!-- <center> -->
                        <img width="260" align="center" src="./index_files/jinpeng/papers/ICIP2020/ICIP_teaser.png" border="0"> &nbsp;
                        <!-- </center> -->
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b> Infrared-Visible Person Re-Identification Via Cross-Modality Batch Normalized Identity Embedding And Mutual Learning</b> <br>
                        <span style="font-size: 10pt;">
                        <span style="font-size: 10pt;"> Yiqi Lin, <a href="https://scholar.google.com.hk/citations?user=nhghITMAAAAJ&hl=en">Andy J. Ma</a>, Jinpeng Wang <br>
                        In ICIP, 2020. <br>
                        [<a href="-">Paper</a>]
                        [<a href="">GitHub</a>]
                        [<a href="">Bibtex</a>]
                        <br>
                    </td>
                </tr>

                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <!-- <center> -->
                          <!-- <center> -->
                        <img width="260" align="center" src="./index_files/jinpeng/papers/ICIG2019/icig_teaser.png" border="0"> &nbsp;
                        <!-- </center> -->
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b> Spatio-Temporal Bottom-Up Top-Down Attention Model for Action Recognition </b> <br>
                        <span style="font-size: 10pt;">
                        <span style="font-size: 10pt;"> Jinpeng Wang, <a href="https://scholar.google.com.hk/citations?user=nhghITMAAAAJ&hl=en">Andy J. Ma</a> <br>
                        In ICIG, 2019. <br>
                        [<a href="https://link.springer.com/chapter/10.1007/978-3-030-34120-6_7">Paper</a>]
                        [<a href="">Bibtex</a>]
                        <br>
                    </td>
                </tr>
            </tbody></table>

        <!--<h2>Thesis </h2>-->
        <!--<font face="helvetica, ariel, &#39;sans serif&#39;">-->
            <!--<table cellspacing="15">-->
                <!--<tbody>-->
                <!--<tr>-->
                    <!--<td width="30%" align=left>-->
                        <!--<img width="250" align="center" src="./index_files/berkeley_logo.png" border="0">-->
                            <!--</td>-->
                    <!--<td>-->
                        <!--<span style="font-size: 12pt;">-->
                        <!--<b>Image Synthesis for Self-Supervised Visual Representation Learning</b> <br>-->
                        <!--<span style="font-size: 10pt;">-->
                        <!--Richard Zhang<br>-->
                        <!--&lt;!&ndash; Commitee: Alexei A. Efros, Trevor Darrell, Michael DeWeese.<br> &ndash;&gt;-->
                        <!--Spring 2018.<br>-->
                        <!--[<a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-36.html">Thesis</a>]-->
                        <!--[<a href="https://www.youtube.com/watch?v=aGhYitrOJRc">Dissertation Talk</a>]-->
                        <!--[<a href="https://youtu.be/IXG-uWFAkmM">Fast Forward</a>]-->
                        <!--[<a href="https://www.dropbox.com/s/96f0xhfwvjnbf52/presentation_dissertation.pptx?dl=0">Slides</a> (396 MB)]-->
                        <!--[<a href="./index_files/bibtex_thesis.txt">Bibtex</a>]-->
                        <!--<br>-->
                    <!--</td>-->
                <!--</tr>-->
            <!--</tbody></table>-->

        <h2>Awards </h2>
        <span style="font-size: 10pt;">
        2021 Excellent Graduation Thesis (1/224). <br>
        Reviewer recognitions, CVPR 2021, ICCV 2021, AAAI 2021, TCSVT.<br>
        The First Prize Scholarship (2020).<br>
        Second Prize of College Students Innovation and Entrepreneurship Competition (2018).<br>
        Excellent undergraduate thesis (2017).<br>
        </span>


<!--         <font face="helvetica, ariel, &#39;sans serif&#39;">
            <table cellspacing="25">
                <tbody>
                <tr>
                    <td width="30%" align="center">
                        <img height="75" horizontal-align="center" src="./index_files/Adobe-logo.png" border="0">
                            </td>
                    <td>
                        <a href="https://research.adobe.com/fellowship/">Adobe Research Fellowship</a> 2017
                    </td>
                </tr>
            </tbody></table>
        </font> -->
        <br>

        <h2>Collaborators</h2>
        I have gotten to work with some wonderful collaborators.<br>

        <!-- <h3>Internship </h3> -->
<!--         <br>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <span style="font-size: 10pt;">
            If you have similar interests and are interested in collaborating during a summer 2021 internship, please feel free to contact me! Tell me about your past research experience and what you would potentially like to do. The goal of an internship is a publication, usually CVPR or SIGGRAPH. For example, see my NIPS 2017 and CVPR 2018 papers, which were from my summer 2017 internship. Interns are almost all PhD students; the number of slots is limited, so we unfortunately cannot accept everyone.<br>
            </span>
        </font> -->

        <!-- <h3>@Adobe</h3> -->
        <br>
        <!-- <h3>@Berkeley</h3> -->
        <!-- <br> -->
        <!--<span style="font-size: 14pt;">-->
               <!--<img width="60" align="center" src="imgs/Tencent_arc.jpg" border="0"> &nbsp;<b>@Tencent PCG ARC Lab (2021.5-2021.7)</b>-->
        <!--</span>-->

        <!--<span style="font-size: 10pt;">-->
        <!--<dl class="dl-horizontal">-->

        <!--</dl>-->

        <span style="font-size: 14pt;">
               <img width="60" align="center" src="imgs/logo-youtu.png" border="0"> &nbsp;<b>@Tencent Youtu Lab(2020.5-2020.9)</b>
        </span>

        <span style="font-size: 10pt;">
        <dl class="dl-horizontal">
            <a href="https://www.sunxing.org">Xin Sun</a>, @HKU <br>
            <a href="https://mac.xmu.edu.cn/rrji_en/">Rongrong Ji</a>, Professor of @XiaMen University<br>

        </dl>

        <!-- </p> -->
        </span>
        <span style="font-size: 14pt;">
            <img width="60" align="center" src="imgs/Sun_Yat-sen_University_Logo.png" border="0"> <b>@Sun Yat-sen University (2013.8-2021.6)</b>
        </span>

        <span style="font-size: 10pt;">
        <dl class="dl-horizontal">
            <a href="http://www.cs.jhu.edu/~andyjhma/index.html">Andy Jinhua Ma</a>, Associate Professor <br>

        </dl>

        <!-- </p> -->
        </span>
        <!-- </p><hr size="2" align="left" noshade=""> -->


        <!--<h2>Teaching </h2>-->
        <!--&lt;!&ndash; <a href="https://research.adobe.com/fellowship/">Adobe Research Fellowship</a> 2017 &ndash;&gt;-->
        <!--<span style="font-size: 12pt;">-->
        <!--<b>Introduction to Artificial Intelligence (CS 188)</b>, UC Berkeley <br>-->
        <!--<span style="font-size: 10pt;">-->
        <!--Graduate Student Instructor (GSI) with Prof. <a href="http://people.eecs.berkeley.edu/~anca/">Anca Dragan</a> <br>-->
        <!--Spring 2017<br>-->
        <!--<br>-->
        <!--<span style="font-size: 12pt;">-->
        <!--<b>Computer Vision (CS 280)</b>, UC Berkeley <br>-->
        <!--<span style="font-size: 10pt;">-->
        <!--Graduate Student Instructor (GSI) with Prof. <a href="http://people.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>, Prof. <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a> <br>-->
        <!--Spring 2016<br>-->
        <!--<br>-->
        <!--<span style="font-size: 12pt;">-->
        <!--<b>Introduction to Circuits (ECE 2100)</b>, Cornell University <br>-->
        <!--<span style="font-size: 10pt;">-->
        <!--Teaching Assistant (TA) with Prof. <a href="https://molnargroup.ece.cornell.edu/">Alyosha Molnar</a> <br>-->
        <!--Spring 2010<br>-->
        <!--<br>-->
            <!--<iframe src="//player.bilibili.com/player.html?aid=247300958&bvid=BV1tv41187Pk&cid=316899973&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>-->
        <h2>Talk</h2>
        <table border="1">
        <tr>
            <td>
            <b> Time:</b> 2021.2.12; <b> Title:</b> CVPR21 BE Demo; <b> Source:</b> Youtube
            <p align="center">
           <iframe width="430" height="300" src="https://www.youtube.com/embed/aFzno6CQcyE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe>
              </p>
            </td>
            <td>
                <b> Time:</b> 2021.3.29;  <b> Title:</b> VALSE STUDENT WEBINAR;  <b> Source:</b> Bilibili (China)
            <p align="center">
            <iframe width="430" height="300" src="//player.bilibili.com/player.html?aid=247300958&bvid=BV1tv41187Pk&cid=316899973&page=1" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe>
            </p>
            </td>
        </tr>
        </table>


        <h2>Visitors</h2>
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=YbPKF1QuCrlgXX8mwopH6mb4xLtY9uixfzcI2QNBsJA'></script>

            <h2>More information</h2>
        Confused by the contents of this page? You can contact with my email.
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75897335-1', 'auto');
  ga('send', 'pageview');
</script>

</font></td></tr></tbody></table><iframe frameborder="0" scrolling="no" style="border: 0px; display: none; background-color: transparent;"></iframe><div id="GOOGLE_INPUT_CHEXT_FLAG" input="null" input_stat="{&quot;tlang&quot;:true,&quot;tsbc&quot;:true,&quot;pun&quot;:true,&quot;mk&quot;:false,&quot;ss&quot;:true}" style="display: none;"></div></body></html>

